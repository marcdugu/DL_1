{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c9a7927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import random\n",
    "from tqdm import trange\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bdff840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'Xtest'])\n"
     ]
    }
   ],
   "source": [
    "# Load and scale training data\n",
    "train_mat = scipy.io.loadmat('Xtrain.mat')\n",
    "train_data = train_mat['Xtrain'].flatten().reshape(-1, 1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(train_data)\n",
    "\n",
    "# Load real test data\n",
    "test_mat = scipy.io.loadmat('Xtest.mat')  \n",
    "print(test_mat.keys())  # Check available keys\n",
    "test_data = test_mat['Xtest'].flatten()  # Replace 'Xtest' with actual key if different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d15967fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_sizes[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_sizes[1], 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b88eacd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hidden_sizes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the saved file with the best model and its configuration\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m final_model = FeedForwardNN(n_steps, \u001b[43mhidden_sizes\u001b[49m, dropout_rate)\n\u001b[32m      3\u001b[39m checkpoint = torch.load(\u001b[33m'\u001b[39m\u001b[33mbest_model.pth\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Extract saved data\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'hidden_sizes' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the saved file with the best model and its configuration\n",
    "checkpoint = torch.load('best_model.pth')\n",
    "\n",
    "# Extract saved data\n",
    "model_state_dict = checkpoint['model_state_dict']\n",
    "best_config = checkpoint['config']  # (n_steps, lr, hidden_sizes, drop_out)\n",
    "best_train_loss = checkpoint['val_loss']\n",
    "model = FeedForwardNN(best_config[0], best_config[2], best_config[3])\n",
    "model.load_state_dict(torch.load('best_model.pth', weights_only=True))\n",
    "\n",
    "# Prepare forecasting seed\n",
    "n_steps = best_config[0]  # n_steps from your best model config\n",
    "seed_seq = list(scaled[-n_steps:].flatten())  # last window from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17da18ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled MSE:  0.000149\n",
      "Sclaed RMSE: 0.012189\n",
      "Real MSE:  9.510091\n",
      "Real RMSE: 3.083844\n"
     ]
    }
   ],
   "source": [
    "# - best_train_loss (MSE on scaled data)\n",
    "# - scaler (MinMaxScaler used on target data)\n",
    "\n",
    "# 1. Scaled metrics\n",
    "mse_scaled = best_train_loss\n",
    "rmse_scaled = mse_scaled ** 0.5\n",
    "\n",
    "# 2. Unscaled metrics\n",
    "range_ = scaler.data_max_ - scaler.data_min_\n",
    "mse_unscaled = mse_scaled * (range_[0] ** 2)\n",
    "rmse_unscaled = rmse_scaled * range_[0]\n",
    "\n",
    "# 3. Print all\n",
    "print(f\"Scaled MSE:  {mse_scaled:.6f}\")\n",
    "print(f\"Sclaed RMSE: {rmse_scaled:.6f}\")\n",
    "print(f\"Real MSE:  {mse_unscaled:.6f}\")\n",
    "print(f\"Real RMSE: {rmse_unscaled:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9653d7b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Step 4: Forecast as many steps as in test set\u001b[39;00m\n\u001b[32m     19\u001b[39m n_future = \u001b[38;5;28mlen\u001b[39m(test_data)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m predictions = \u001b[43mrecursive_forecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_future\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mrecursive_forecast\u001b[39m\u001b[34m(model, seed_seq, n_future, scaler)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrecursive_forecast\u001b[39m(model, seed_seq, n_future, scaler):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m()\n\u001b[32m      5\u001b[39m     forecast = []\n\u001b[32m      6\u001b[39m     input_seq = seed_seq.copy()\n",
      "\u001b[31mAttributeError\u001b[39m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "# ----  Recursive Forecasting Function ----\n",
    "\n",
    "def recursive_forecast(model, seed_seq, n_future, scaler):\n",
    "    model.eval()\n",
    "    forecast = []\n",
    "    input_seq = seed_seq.copy()\n",
    "\n",
    "    for _ in range(n_future):\n",
    "        input_tensor = torch.tensor(input_seq, dtype=torch.float32).view(1, -1)\n",
    "        with torch.no_grad():\n",
    "            next_val = model(input_tensor).item()\n",
    "        forecast.append(next_val)\n",
    "        input_seq = input_seq[1:] + [next_val]  # Slide the window\n",
    "\n",
    "    forecast = scaler.inverse_transform(np.array(forecast).reshape(-1, 1))\n",
    "    return forecast.flatten()\n",
    "\n",
    "# Step 4: Forecast as many steps as in test set\n",
    "n_future = len(test_data)\n",
    "predictions = recursive_forecast(model, seed_seq, n_future, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8017b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Evaluate\n",
    "mae = mean_absolute_error(test_data, predictions)\n",
    "mse = mean_squared_error(test_data, predictions)\n",
    "\n",
    "print(f\"Training Loss: {best_train_loss}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a103cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Prepare full plot range (seed + forecast)\n",
    "seed_real = scaler.inverse_transform(np.array(seed_seq).reshape(-1, 1)).flatten()\n",
    "\n",
    "# Step 7: Plot seed, predicted, and actual test data\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(np.arange(len(seed_real)), seed_real, label='Seed Input (History)', color='gray')\n",
    "plt.plot(np.arange(len(seed_real), len(seed_real) + n_future), test_data, label='Actual Test Data', color='blue')\n",
    "plt.plot(np.arange(len(seed_real), len(seed_real) + n_future), predictions, label='Predicted Values', color='red', linestyle='--')\n",
    "plt.title('Recursive Forecast vs Actual Test Data')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_unir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
